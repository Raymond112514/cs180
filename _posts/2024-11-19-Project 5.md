---
layout: post
---

## Part A: The Power of Diffusion Models!

### A.1 Forward Process

Before diving into diffusion models, we first focus on the problem of denoisingâ€”removing noise from noisy images. The data we will use consists of a collection of noisy images at different scales. The noisy image is defined as:  

$$x_{noised} = x + \sigma \epsilon$$  

where $x$ denote the clean image and $\epsilon \sim N(0, 1)$.  

We show a few examples of noisy images at scales $250$, $500$, and $700$, respectively, in the figure below.  

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_1.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Noised images of different scale.</p>

### A.2 Classical Denoising

We now attempt to denoise the images. The classical approach to denoising is to apply a Gaussian filter, as shown below.

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_2.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 2:</strong> Gaussian denoising (Top row) Noisy image (Bottom row) Gaussian denoised images.</p>

Note that the Gaussian filter is not sufficient to completely remove the noise.

### A.3 One-Step Denoising

We now use a pretrained diffusion model for denoising. Specifically, we utilize the DeepFloyd IF diffusion model, which supports text prompts. Below, we showcase some examples of DeepFloyd IF generations along with their corresponding prompts.

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/samples.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 3:</strong> Sample generation of DeepFloyd model. </p>

Using the UNet architecture from the denoiser, we apply single-step denoising. The results are presented below.

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_3.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 4:</strong> One step denoised images (Top) Noisy image (Bottom) One-step denoised image. For the original image, see Figure 6. </p>

Note that the denoised results are significantly better compared to Gaussian denoising.

### A.4 Iterative Denoising

To further improve the performance of denoising, we can increase the number of steps, leading to an iterative denoising method. To simplify the calculations, we used strided timesteps. The noised images are shown below.

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_4_traj.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 5:</strong> Noisy images.</p>

Comparing the results of iterative denoising with other methods, we observe that iterative denoising provides the best results with the finest details.

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_4_compare.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 6:</strong> Comparison of different methods.</p>

### A.5 Diffusion Model Sampling

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_5.png" alt="Image 1" style="width: 100%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

### A.6 Classifier-Free Guidance (CFG)

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_6.png" alt="Image 1" style="width: 100%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

### A.7 Image-to-image Translation
#### SDE Edit

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_7_1.png" alt="Image 1" style="width: 100%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_7_2.png" alt="Image 1" style="width: 100%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

#### Inpainting

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_7_3.png" alt="Image 1" style="width: 100%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

#### Text-Conditional Image-to-image Translation

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_7_4.png" alt="Image 1" style="width: 100%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

### A.8 Visual Anagrams

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_8.png" alt="Image 1" style="width: 100%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

### A.9 Hybrid Images

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/1_9.png" alt="Image 1" style="width: 100%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

## Part B: Diffusion Models

### Denoiser Model

We now implement diffusion model froms scratch. Before implementing the diffusion model, we start by implementing a denoiser, which takes in a noised images and tries to remove the noise present in the image. To do so, we used the U-Net architecture as follows. The dataset is MNIST that has benn corrupted with additive noise, as follows

$$z_i=x_i+\sigma \epsilon_i$$

We show the impact of different noise in the figure below.

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/noise_visualization.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

The network, during training, takes in a noised image and tries to output the desnoised image, the stochastic loss is then defined by 

$$ L =\frac{1}{n}\sum_{i=1}^n ||D_{\theta}(x_i+\sigma\epsilon_i) - x_i||_2^2$$

For the purpose of our training, we set $\sigma=0.5$. The network is trained for $5$ epochs with Adam optimizer with learning rate $10^{-4}$ and batch size of $32$. The training loss curve is shown below. 

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/denoiser_loss_curve.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

We dispplay the denoising result after the 1st and 5th epochs as below.

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/epoch_one_result_denoise.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/epoch_five_result_denoise.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

We see that the model successfully removed the noises and recovered the handwritten images. We can also test the models' performance on different noise level. From the figure below, we can see that our model is qwuite robust at different noise levels, despite not being trained on them.

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/diff_schedule.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

### Diffusion Model

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/diffusion_loss_curve.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/diffusion_visual.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

### Diffusion Model With Class Conditioning

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/class_diffusion_loss.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>

<div style="display: flex; justify-content: center;">   
   <img src="{{ site.baseurl }}/assets/proj5_images/class_diffusion_visual.png" alt="Image 1" style="width: 90%; height: auto;"> 
</div> 
<p style="text-align: center; margin-top: 15px;"><strong>Figure 1:</strong> Labeled source and target images.</p>





